{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0836a9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\BASHEER-\n",
      "[nltk_data]     PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from  sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecca79b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "      <th>log_price</th>\n",
       "      <th>name_processed</th>\n",
       "      <th>brand_name_processed</th>\n",
       "      <th>category_name_preprocessed</th>\n",
       "      <th>Tier_1</th>\n",
       "      <th>Tier_2</th>\n",
       "      <th>Tier_3</th>\n",
       "      <th>processed_item_description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLB Cincinnati Reds T Shirt Size XL</td>\n",
       "      <td>3</td>\n",
       "      <td>Men/Tops/T-shirts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>No description yet</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>mlb cincinnati reds shirt size xl</td>\n",
       "      <td>mlb</td>\n",
       "      <td>men/top/tshirts</td>\n",
       "      <td>men</td>\n",
       "      <td>top</td>\n",
       "      <td>tshirts</td>\n",
       "      <td>description yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Razer BlackWidow Chroma Keyboard</td>\n",
       "      <td>3</td>\n",
       "      <td>Electronics/Computers &amp; Tablets/Components &amp; P...</td>\n",
       "      <td>Razer</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>This keyboard is in great condition and works ...</td>\n",
       "      <td>3.970292</td>\n",
       "      <td>razer blackwidow chroma keyboard</td>\n",
       "      <td>razer</td>\n",
       "      <td>electronic/computer tablet/component parts</td>\n",
       "      <td>electronic</td>\n",
       "      <td>computer tablet</td>\n",
       "      <td>component parts</td>\n",
       "      <td>keyboard great condition works like came box p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AVA-VIV Blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Tops &amp; Blouses/Blouse</td>\n",
       "      <td>Target</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Adorable top with a hint of lace and a key hol...</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>avaviv blouse</td>\n",
       "      <td>target</td>\n",
       "      <td>women/top blouse/blouse</td>\n",
       "      <td>women</td>\n",
       "      <td>top blouse</td>\n",
       "      <td>blouse</td>\n",
       "      <td>adorable top hint lace key hole back pale pink...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leather Horse Statues</td>\n",
       "      <td>1</td>\n",
       "      <td>Home/Home Décor/Home Décor Accents</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>New with tags. Leather horses. Retail for [rm]...</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>leather horse statues</td>\n",
       "      <td>missing</td>\n",
       "      <td>home/home dcor/home dcor accents</td>\n",
       "      <td>home</td>\n",
       "      <td>home dcor</td>\n",
       "      <td>home dcor accents</td>\n",
       "      <td>new tags leather horses retail stand foot high...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24K GOLD plated rose</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Jewelry/Necklaces</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Complete with certificate of authenticity</td>\n",
       "      <td>3.806662</td>\n",
       "      <td>24k gold plated rose</td>\n",
       "      <td>missing</td>\n",
       "      <td>women/jewelry/necklaces</td>\n",
       "      <td>women</td>\n",
       "      <td>jewelry</td>\n",
       "      <td>necklaces</td>\n",
       "      <td>complete certificate authenticity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482530</th>\n",
       "      <td>Free People Inspired Dress</td>\n",
       "      <td>2</td>\n",
       "      <td>Women/Dresses/Mid-Calf</td>\n",
       "      <td>Free People</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Lace, says size small but fits medium perfectl...</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>free people inspired dress</td>\n",
       "      <td>free people</td>\n",
       "      <td>women/dresse/midcalf</td>\n",
       "      <td>women</td>\n",
       "      <td>dresse</td>\n",
       "      <td>midcalf</td>\n",
       "      <td>lace says size small fits medium perfectly nev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482531</th>\n",
       "      <td>Little mermaid handmade dress</td>\n",
       "      <td>2</td>\n",
       "      <td>Kids/Girls 2T-5T/Dresses</td>\n",
       "      <td>Disney</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Little mermaid handmade dress never worn size 2t</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>little mermaid handmade dress</td>\n",
       "      <td>disney</td>\n",
       "      <td>kid/girl 2t5t/dresses</td>\n",
       "      <td>kid</td>\n",
       "      <td>girl 2t5t</td>\n",
       "      <td>dresses</td>\n",
       "      <td>little mermaid handmade dress never worn size 2t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482532</th>\n",
       "      <td>21 day fix containers and eating plan</td>\n",
       "      <td>2</td>\n",
       "      <td>Sports &amp; Outdoors/Exercise/Fitness accessories</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Used once or twice, still in great shape.</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>21 day fix containers eating plan</td>\n",
       "      <td>missing</td>\n",
       "      <td>sport outdoor/exercise/fitnes accessories</td>\n",
       "      <td>sport outdoor</td>\n",
       "      <td>exercise</td>\n",
       "      <td>fitnes accessories</td>\n",
       "      <td>used twice still great shape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482533</th>\n",
       "      <td>World markets lanterns</td>\n",
       "      <td>3</td>\n",
       "      <td>Home/Home Décor/Home Décor Accents</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "      <td>There is 2 of each one that you see! So 2 red ...</td>\n",
       "      <td>3.828641</td>\n",
       "      <td>world markets lanterns</td>\n",
       "      <td>missing</td>\n",
       "      <td>home/home dcor/home dcor accents</td>\n",
       "      <td>home</td>\n",
       "      <td>home dcor</td>\n",
       "      <td>home dcor accents</td>\n",
       "      <td>2 one see 2 red 2 orange 2 big red orange ones...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482534</th>\n",
       "      <td>Brand new lux de ville wallet</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Women's Accessories/Wallets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>New with tag, red with sparkle. Firm price, no...</td>\n",
       "      <td>3.135494</td>\n",
       "      <td>brand new lux de ville wallet</td>\n",
       "      <td>lux</td>\n",
       "      <td>women/women accessorie/wallets</td>\n",
       "      <td>women</td>\n",
       "      <td>women accessorie</td>\n",
       "      <td>wallets</td>\n",
       "      <td>new tag red sparkle firm price free shipping</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1482535 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           name  item_condition_id  \\\n",
       "train_id                                                             \n",
       "0           MLB Cincinnati Reds T Shirt Size XL                  3   \n",
       "1              Razer BlackWidow Chroma Keyboard                  3   \n",
       "2                                AVA-VIV Blouse                  1   \n",
       "3                         Leather Horse Statues                  1   \n",
       "4                          24K GOLD plated rose                  1   \n",
       "...                                         ...                ...   \n",
       "1482530              Free People Inspired Dress                  2   \n",
       "1482531           Little mermaid handmade dress                  2   \n",
       "1482532   21 day fix containers and eating plan                  2   \n",
       "1482533                  World markets lanterns                  3   \n",
       "1482534           Brand new lux de ville wallet                  1   \n",
       "\n",
       "                                              category_name   brand_name  \\\n",
       "train_id                                                                   \n",
       "0                                         Men/Tops/T-shirts          NaN   \n",
       "1         Electronics/Computers & Tablets/Components & P...        Razer   \n",
       "2                               Women/Tops & Blouses/Blouse       Target   \n",
       "3                        Home/Home Décor/Home Décor Accents          NaN   \n",
       "4                                   Women/Jewelry/Necklaces          NaN   \n",
       "...                                                     ...          ...   \n",
       "1482530                              Women/Dresses/Mid-Calf  Free People   \n",
       "1482531                            Kids/Girls 2T-5T/Dresses       Disney   \n",
       "1482532      Sports & Outdoors/Exercise/Fitness accessories          NaN   \n",
       "1482533                  Home/Home Décor/Home Décor Accents          NaN   \n",
       "1482534                   Women/Women's Accessories/Wallets          NaN   \n",
       "\n",
       "          price  shipping                                   item_description  \\\n",
       "train_id                                                                       \n",
       "0          10.0         1                                 No description yet   \n",
       "1          52.0         0  This keyboard is in great condition and works ...   \n",
       "2          10.0         1  Adorable top with a hint of lace and a key hol...   \n",
       "3          35.0         1  New with tags. Leather horses. Retail for [rm]...   \n",
       "4          44.0         0          Complete with certificate of authenticity   \n",
       "...         ...       ...                                                ...   \n",
       "1482530    20.0         1  Lace, says size small but fits medium perfectl...   \n",
       "1482531    14.0         0   Little mermaid handmade dress never worn size 2t   \n",
       "1482532    12.0         0          Used once or twice, still in great shape.   \n",
       "1482533    45.0         1  There is 2 of each one that you see! So 2 red ...   \n",
       "1482534    22.0         0  New with tag, red with sparkle. Firm price, no...   \n",
       "\n",
       "          log_price                     name_processed brand_name_processed  \\\n",
       "train_id                                                                      \n",
       "0          2.397895  mlb cincinnati reds shirt size xl                  mlb   \n",
       "1          3.970292   razer blackwidow chroma keyboard                razer   \n",
       "2          2.397895                      avaviv blouse               target   \n",
       "3          3.583519              leather horse statues              missing   \n",
       "4          3.806662               24k gold plated rose              missing   \n",
       "...             ...                                ...                  ...   \n",
       "1482530    3.044522         free people inspired dress          free people   \n",
       "1482531    2.708050      little mermaid handmade dress               disney   \n",
       "1482532    2.564949  21 day fix containers eating plan              missing   \n",
       "1482533    3.828641             world markets lanterns              missing   \n",
       "1482534    3.135494      brand new lux de ville wallet                  lux   \n",
       "\n",
       "                          category_name_preprocessed         Tier_1  \\\n",
       "train_id                                                              \n",
       "0                                    men/top/tshirts            men   \n",
       "1         electronic/computer tablet/component parts     electronic   \n",
       "2                            women/top blouse/blouse          women   \n",
       "3                   home/home dcor/home dcor accents           home   \n",
       "4                            women/jewelry/necklaces          women   \n",
       "...                                              ...            ...   \n",
       "1482530                         women/dresse/midcalf          women   \n",
       "1482531                        kid/girl 2t5t/dresses            kid   \n",
       "1482532    sport outdoor/exercise/fitnes accessories  sport outdoor   \n",
       "1482533             home/home dcor/home dcor accents           home   \n",
       "1482534               women/women accessorie/wallets          women   \n",
       "\n",
       "                    Tier_2              Tier_3  \\\n",
       "train_id                                         \n",
       "0                      top             tshirts   \n",
       "1          computer tablet     component parts   \n",
       "2               top blouse              blouse   \n",
       "3                home dcor   home dcor accents   \n",
       "4                  jewelry           necklaces   \n",
       "...                    ...                 ...   \n",
       "1482530             dresse             midcalf   \n",
       "1482531          girl 2t5t             dresses   \n",
       "1482532           exercise  fitnes accessories   \n",
       "1482533          home dcor   home dcor accents   \n",
       "1482534   women accessorie             wallets   \n",
       "\n",
       "                                 processed_item_description  \n",
       "train_id                                                     \n",
       "0                                           description yet  \n",
       "1         keyboard great condition works like came box p...  \n",
       "2         adorable top hint lace key hole back pale pink...  \n",
       "3         new tags leather horses retail stand foot high...  \n",
       "4                         complete certificate authenticity  \n",
       "...                                                     ...  \n",
       "1482530   lace says size small fits medium perfectly nev...  \n",
       "1482531    little mermaid handmade dress never worn size 2t  \n",
       "1482532                        used twice still great shape  \n",
       "1482533   2 one see 2 red 2 orange 2 big red orange ones...  \n",
       "1482534        new tag red sparkle firm price free shipping  \n",
       "\n",
       "[1482535 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOADING THE TRAIN DATASET\n",
    "\n",
    "df= pd.read_csv(\"train_processed.csv\",index_col = [\"train_id\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f02abebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLITTING THE DATASET\n",
    "df_train,df_val = train_test_split(df,test_size=0.1,random_state = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb0d93b",
   "metadata": {},
   "source": [
    "## Function 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedd06ba",
   "metadata": {},
   "source": [
    "**THIS FUNCTION TAKES DATAFRAME AS INPUT AND RETURNS PREDICTION AS OUTPUT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccffd982",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''THIS FUNCTION TOKENIZES AND PADS THE FEATURE'''\n",
    "\n",
    "def text_vectorizer(feature):\n",
    "    # TOKENIZER\n",
    "    tk = Tokenizer()\n",
    "    # FIT ON TRAIN \n",
    "    tk.fit_on_texts(df_train[feature].apply(str))\n",
    "    # TOKENIZES THE TRAIN DATASET\n",
    "    tk_train = tk.texts_to_sequences(df_train[feature].apply(str))\n",
    "    # TOKENIZES THE VALIDATION DATASET\n",
    "    tk_val = tk.texts_to_sequences(df_val[feature].apply(str))\n",
    "    \n",
    "    # COMPUTES THE MAX LENGTH\n",
    "    max_length = df_train[feature].apply(lambda x :len(str(x).split())).max()\n",
    "    \n",
    "    # COMPUTE THE VOCAB SIZE\n",
    "    vocab_size = len(tk.word_index) + 1\n",
    "    \n",
    "    # PADDING THE TRAIN SEQUENCES\n",
    "    #train_pad= pad_sequences(tk_train,padding=\"post\",maxlen = max_length)\n",
    "    # PADDING THE VALIDATION SEQUENCES\n",
    "    #val_pad = pad_sequences(tk_val,padding = \"post\", maxlen = max_length)\n",
    "    \n",
    "    # RETURN THE TOKENIZER, MAX LENGTH , PADDED TRAIN SEQUENCES , PADDED VALIDATION SEQUENCES \n",
    "    return tk , max_length,vocab_size\n",
    "#, train_pad , val_pad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a6a4a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function1(df1):\n",
    "\n",
    "    df_raw = df1 # STORING THE INPUT DATAFRAME\n",
    "\n",
    "  #ITEM CONDITON ID FEATURE\n",
    "    item_cond = df_raw.item_condition_id # STORING THE ITEM CONDITION ID\n",
    "\n",
    "  #######################################\n",
    "\n",
    "  # SHIPPING FEATURE\n",
    "    shipping = df_raw.shipping # STORING THE SHIPPING \n",
    "\n",
    "  ########################################\n",
    "\n",
    "  # NAME FEATURE\n",
    "\n",
    "  # Ref: https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
    "    def decontracted(phrase):\n",
    "        '''THIS FUNCTION DECONTRACTS THE TEXT'''\n",
    "      # specific\n",
    "        phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "        phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "      # general\n",
    "        phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "        phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "        phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "        phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "        phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "        phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "        phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "        phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "        return phrase\n",
    "    \n",
    "\n",
    "    st_words = stopwords.words('english') # STORING STOPWORDS \n",
    "\n",
    "    def name_process(text):\n",
    "        '''THIS FUNCTION IS USED TO PREPROCESS THE NAME FEATURE'''\n",
    "        \n",
    "        text = decontracted(text) # DECONTRACTION\n",
    "        text = re.sub(\"[^A-Za-z0-9 ]\",\"\",text) # REMOVE EVERYTHING EXCEPT THE PROVIDED CHARACTERS\n",
    "        text = text.lower() # CONVERT TO LOWER CASE\n",
    "        text =  \" \".join([i for i in text.split() if i not in st_words])\n",
    "        if len(text)==0:\n",
    "            text = \"missing\"\n",
    "        return text # RETURN THE OUTPUT TEXT\n",
    "    \n",
    "\n",
    "    df_raw[\"name_processed\"] = df_raw.name.apply(name_process) # STORING PREPROCESSD DATA IN DATAFRAME\n",
    "    df_raw[df_raw.name_processed.isnull()].name_processed =\"missing\"  # INPUTING NULL FOR MISSING \n",
    "    \n",
    "    # TOKENIZING  \n",
    "    tk_name_processed , max_length_name_processed ,vocab_size_name_processed = text_vectorizer(\"name_processed\")\n",
    "    # PADDING\n",
    "    name_pad = pad_sequences(tk_name_processed.texts_to_sequences(df_raw.name_processed),maxlen=max_length_name_processed,padding=\"post\")\n",
    "\n",
    "##########################################################################################################################\n",
    "\n",
    "  ## BRAND NAME FEATURE\n",
    "    def brand_process(text):\n",
    "        '''THIS FUNCTION PREPROCESSED THE BRAND NAME'''\n",
    "        text = re.sub(\"[^A-Za-z0-9 ]\",\"\",text)# REMOVE EVERYTHING EXCEPT THE PROVIDED CHARACTERS\n",
    "        text = text.lower()  # CONVERT TO LOWER CASE\n",
    "        return text\n",
    "    \n",
    "    '''THIS LOOP EXTRACTS BRAND NAME FROM NAME'''\n",
    "    brand_score = dict(df[df.brand_name.notnull()][\"brand_name\"].apply(brand_process).value_counts())\n",
    "\n",
    "    processed_brand_name = [] #storing the barand name after preprocessing\n",
    "    for index,i in df_raw.iterrows() : # for each row in the dataset\n",
    "      \n",
    "        if  pd.isnull(i.brand_name): #if the brand name isnull we follow this\n",
    "          \n",
    "            words = i.name_processed.split() # we will split the name for that datapoint\n",
    "            score  = [] # this variable stores the score for each word that we calculated above\n",
    "            for j in words: # for each word \n",
    "                if j in brand_score.keys(): #if the words in name is present in the keys of brand score dict\n",
    "                    score.append(brand_score[j]) # take the score from the dict and append in the score variable\n",
    "                else: #if the word is not a brand name append -1\n",
    "                    score.append(-1)\n",
    "          # once we get the scores for all the words in the name the word with maximum score woulb be the brand name\n",
    "            if max(score) > 0: #if the maximum score is greater than 0 then it contains a brand name so we append the brand name\n",
    "                processed_brand_name.append(words[score.index(max(score))])\n",
    "            else: # if maximum value is less than 0 then it means no brand name was found so \"missing\" is appended\n",
    "                processed_brand_name.append(\"missing\")\n",
    "              \n",
    "        else: # if the brand_name is not null we follow this\n",
    "            processed_brand_name.append(brand_process(i.brand_name))\n",
    "    \n",
    "    # STORES THE PROCESSED BRAND NAME IN DATAFRAME\n",
    "    df_raw[\"brand_name_processed\"] = processed_brand_name\n",
    "    \n",
    "    # TOKENIZING\n",
    "    tk_brand_name,max_length_brand_name,vocab_size_brand_name = text_vectorizer(\"brand_name_processed\")\n",
    "    # PADDING\n",
    "    brand_name_pad = pad_sequences(tk_brand_name.texts_to_sequences(df_raw.brand_name_processed),maxlen=max_length_brand_name,padding=\"post\")\n",
    "\n",
    "  ########################################################################################################################################\n",
    "\n",
    "  ### CATEGORY NAME\n",
    "    def category_name_preprocessing(text):\n",
    "        ''' THIS FUNCTION PREPROCESSES THE TEXT IN \"category_name\" FEATURE'''\n",
    "        \n",
    "        text = re.sub(\"[^A-Za-z0-9/ ]\",\"\",text)# REMOVING ALL THE TEXT EXCEPT THE GIVEN CHARACTERS\n",
    "        text = re.sub(\"s \",\" \",text) # REMOVING  \"s\" AT THE END OF THE WORD\n",
    "        text = re.sub(\"s/\",\"/\",text) # REMOVING  \"s\" AT THE END OF THE WORD\n",
    "        text = re.sub(\"  \",\" \",text) # REMOVING ONE SPACE WHERE TWO SPACES ARE PRESENT\n",
    "        text = text.lower() # CONVERTING THE TEXT TO LOWER CASE\n",
    "        return text # RETURNING THE PROCESSED TEXT\n",
    "    \n",
    "    # \"missing\" TO NULL VALUES\n",
    "    df_raw.category_name[df_raw.category_name.isnull()] = \"missing\"\n",
    "    # PREPROCESS CATEGORY NAME\n",
    "    df_raw[\"category_name_preprocessed\"] = df_raw.category_name.apply(category_name_preprocessing)\n",
    "    \n",
    "    # EXTRACT TIER 1\n",
    "    df_raw[\"Tier_1\"] = df_raw.category_name_preprocessed.apply(lambda x:   x.split(\"/\")[0] if len(x.split(\"/\"))>=1 else \"missing\")\n",
    "    # TOKENIZING AND PAGGING\n",
    "    tk_tier1 , max_length_tier1 ,vocab_size_tier1 = text_vectorizer(\"Tier_1\")\n",
    "    tier1_pad = pad_sequences(tk_tier1.texts_to_sequences(df_raw.Tier_1),maxlen=max_length_tier1,padding=\"post\")\n",
    "    \n",
    "    # EXTRACI TIER 2\n",
    "    df_raw[\"Tier_2\"] = df_raw.category_name_preprocessed.apply(lambda x:   x.split(\"/\")[1] if len(x.split(\"/\"))>1 else \"missing\")\n",
    "    # TOKENIZING AND PADDING  \n",
    "    tk_tier2 , max_length_tier2 ,vocab_size_tier2 = text_vectorizer(\"Tier_2\")\n",
    "    tier2_pad = pad_sequences(tk_tier2.texts_to_sequences(df_raw.Tier_2),maxlen=max_length_tier2,padding=\"post\")\n",
    "    \n",
    "    # EXTRACT TIER3\n",
    "    df_raw[\"Tier_3\"] = df_raw.category_name_preprocessed.apply(lambda x:   x.split(\"/\")[2] if len(x.split(\"/\"))>1 else \"missing\")\n",
    "    #TOKENIZING AND PADDING\n",
    "    tk_tier3 , max_length_tier3 ,vocab_size_tier3 = text_vectorizer(\"Tier_3\")\n",
    "    tier3_pad = pad_sequences(tk_tier3.texts_to_sequences(df_raw.Tier_3),maxlen=max_length_tier3,padding=\"post\")\n",
    "  #########################################################################################################################################\n",
    "\n",
    "  # ITEM DESCRIPTION \n",
    "    \n",
    "    def processing_item_description(text):\n",
    "        '''THIS FUNCTION PREPROCESSES THE TEXT IN \"item_description\"'''\n",
    "        text = re.sub(\"\\[rm\\] \",\"\",str(text))\n",
    "        text = decontracted(text)\n",
    "        text = re.sub(\"[^A-Za-z0-9 ]\",\"\",str(text))\n",
    "        text = str(text).lower()\n",
    "        text =  \" \".join([i for i in text.split() if i not in st_words])\n",
    "        if len(text)==0:\n",
    "            text = \"missing\"\n",
    "        return text\n",
    "    # \"missing\" TO NULL VALUES\n",
    "    df_raw.item_description[df_raw.item_description.isnull()]=\"missing\"\n",
    "    df_raw[\"processed_item_description\"] = df_raw.item_description.apply(processing_item_description)\n",
    "    # TOKENIZING AND PADDING\n",
    "    tk_desc , max_len_desc ,vocab_size_desc = text_vectorizer(\"processed_item_description\")\n",
    "    desc_pad = pad_sequences(tk_desc.texts_to_sequences(df_raw.processed_item_description),maxlen=max_len_desc,padding=\"post\")\n",
    "    \n",
    "    # FORMING INPUT TO MODEL BY FORMING LIST OF ALL FEATURES\n",
    "    x = [item_cond,shipping,brand_name_pad,tier1_pad,tier2_pad,tier3_pad,name_pad,desc_pad]\n",
    "\n",
    "  ########################################################################################################################################\n",
    "\n",
    "  # MODEL ARCHITECTURE\n",
    "\n",
    "  # ITEM CONDITION ID\n",
    "    inp1 = layers.Input(shape=(1))\n",
    "    emb1  = layers.Embedding(6,10,input_length=1)(inp1)\n",
    "    flat1 = layers.Flatten()(emb1)\n",
    "\n",
    "  # SHIPPING \n",
    "    inp2 = layers.Input(shape=(1))\n",
    "    d2 = layers.Dense(10,activation=\"relu\")(inp2)\n",
    "\n",
    "  # BRAND NAME\n",
    "    inp3 = layers.Input(shape= (8))\n",
    "    emb3 = layers.Embedding(vocab_size_brand_name ,16 ,input_length= 8 )(inp3)\n",
    "    flat3 = layers.Flatten()(emb3)\n",
    "\n",
    "  # Tier_1\n",
    "    inp4 = layers.Input(shape = (2))\n",
    "    emb4 = layers.Embedding(vocab_size_tier1, 16 , input_length=2 )(inp4)\n",
    "    flat4 = layers.Flatten()(emb4)\n",
    "\n",
    "  # Tier_2\n",
    "    inp5= layers.Input(shape = (4))\n",
    "    emb5 = layers.Embedding(vocab_size_tier2 , 16 ,input_length= 4 )(inp5)\n",
    "    flat5 = layers.Flatten()(emb5)\n",
    "\n",
    "  # Tier_3\n",
    "    inp6= layers.Input(shape = (6))\n",
    "    emb6 = layers.Embedding(vocab_size_tier3, 16 ,input_length= 6 )(inp6)\n",
    "    flat6 = layers.Flatten()(emb6)\n",
    "\n",
    "  # NAME PROCESSED\n",
    "    inp7= layers.Input(shape = (13))\n",
    "    emb7 = layers.Embedding(vocab_size_name_processed,20 ,input_length= 13 )(inp7)\n",
    "    lstm7 = layers.GRU(64,return_sequences=True)(emb7)\n",
    "    flat7 = layers.Flatten()(lstm7)\n",
    "\n",
    "  # ITEM DESCRIPTION\n",
    "    inp8= layers.Input(shape = (193))\n",
    "    emb8 = layers.Embedding(vocab_size_desc , 40 , input_length= 193 )(inp8)\n",
    "    lstm8 = layers.GRU(64,return_sequences=True)(emb8)\n",
    "    flat8 = layers.Flatten()(lstm8)\n",
    "\n",
    "    concat = layers.Concatenate()([flat1,d2,flat3,flat4,flat5,flat6,flat7,flat8])\n",
    "\n",
    "    dense1 = layers.Dense(512,activation=\"relu\")(concat)\n",
    "    drop2 = layers.Dropout(0.2)(dense1)\n",
    "\n",
    "    dense2 = layers.Dense(256,activation=\"relu\")(drop2)\n",
    "    drop2 = layers.Dropout(0.3)(dense2)\n",
    "\n",
    "\n",
    "    dense3 = layers.Dense(128,activation=\"relu\")(drop2)\n",
    "    drop2 = layers.Dropout(0.4)(dense3)\n",
    "    bn2  = layers.BatchNormalization()(drop2)\n",
    "\n",
    "    dense4 = layers.Dense(1,activation=\"linear\")(bn2)\n",
    "\n",
    "    model =  Model(inputs= [inp1,inp2,inp3,inp4,inp5,inp6,inp7,inp8],outputs=dense4)\n",
    "    # COMPILING MODEL\n",
    "    model.compile(optimizer=\"adam\",loss=\"mse\",metrics=  tf.keras.metrics.RootMeanSquaredError())\n",
    "    # LOADING THE WEIGHTS\n",
    "    model.load_weights(\"best.h5\")\n",
    "    \n",
    "    # PREDICT THE OUTPUT\n",
    "    x_pred = model.predict(x,batch_size=100)\n",
    "    \n",
    "    # LOG PRICE TO ACTUAL VALUES\n",
    "    def log_to_actual(log):\n",
    "        return np.exp(log)-1\n",
    "    \n",
    "    # FORING DATAFRAME OF RESULTS\n",
    "    x_pred_df = pd.DataFrame(log_to_actual(x_pred),columns=[\"price\"])\n",
    "\n",
    "    return x_pred_df # RETURN PREDICTIONS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4335c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 740ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.488786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.758106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.984865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.767696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.523535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40.599293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>51.837479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18.560535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.544349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21.807371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       price\n",
       "0   8.488786\n",
       "1  48.758106\n",
       "2  12.984865\n",
       "3  22.767696\n",
       "4  29.523535\n",
       "5  40.599293\n",
       "6  51.837479\n",
       "7  18.560535\n",
       "8  14.544349\n",
       "9  21.807371"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RESULTS OF  FIRST 10 ROWS OF DATAFRAME\n",
    "function1(df[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0b0906a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 595ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.446921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price\n",
       "0  8.446921"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PREDICTION OF ONE DATAPOINT\n",
    "\n",
    "function1(df_val[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad8247e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 673ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.446923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.492451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       price\n",
       "0   8.446923\n",
       "1  13.492451"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function1(df_val[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a9ace7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 573ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.446921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.492451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.166567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.026264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.765070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       price\n",
       "0   8.446921\n",
       "1  13.492451\n",
       "2  25.166567\n",
       "3  18.026264\n",
       "4  16.765070"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function1(df_val[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb4122ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1483/1483 [==============================] - 122s 82ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.446923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.492451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.166567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.026264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.765070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148249</th>\n",
       "      <td>11.129321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148250</th>\n",
       "      <td>10.506555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148251</th>\n",
       "      <td>13.059233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148252</th>\n",
       "      <td>22.025299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148253</th>\n",
       "      <td>8.438562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148254 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            price\n",
       "0        8.446923\n",
       "1       13.492451\n",
       "2       25.166567\n",
       "3       18.026264\n",
       "4       16.765070\n",
       "...           ...\n",
       "148249  11.129321\n",
       "148250  10.506555\n",
       "148251  13.059233\n",
       "148252  22.025299\n",
       "148253   8.438562\n",
       "\n",
       "[148254 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PREDICTION OF VALIDATION DATA\n",
    "function1(df_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0a2348",
   "metadata": {},
   "source": [
    "## Function 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94b950d",
   "metadata": {},
   "source": [
    "**THIS FUNCTION TAKES DATAFRAME AS INPUT AND RETURNS METRIC RMSLE AS OUTPUT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83e7ff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function2(df1,y_price):\n",
    "\n",
    "    df_raw = df1\n",
    "\n",
    "  #ITEM CONDITON ID FEATURE\n",
    "    item_cond = df_raw.item_condition_id\n",
    "\n",
    "  ################################################.\n",
    "\n",
    "  # SHIPPING FEATURE\n",
    "    shipping = df_raw.shipping\n",
    "\n",
    "  #######################################################\n",
    "\n",
    "  # NAME FEATURE\n",
    "\n",
    "  # Ref: https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
    "    def decontracted(phrase):\n",
    "      # specific\n",
    "        phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "        phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "        # general\n",
    "        phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "        phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "        phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "        phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "        phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "        phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "        phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "        phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "        return phrase\n",
    "\n",
    "    st_words = stopwords.words('english')\n",
    "\n",
    "    def name_process(text):\n",
    "        '''THIS FUNCTION IS USED TO PREPROCESS THE NAME FEATURE'''\n",
    "        text = decontracted(text)\n",
    "        text = re.sub(\"[^A-Za-z0-9 ]\",\"\",text) # REMOVE EVERYTHING EXCEPT THE PROVIDED CHARACTERS\n",
    "        text = text.lower() # CONVERT TO LOWER CASE\n",
    "        text =  \" \".join([i for i in text.split() if i not in st_words])\n",
    "        if len(text)==0:\n",
    "            text = \"missing\"\n",
    "        return text # RETURN THE OUTPUT TEXT\n",
    "\n",
    "    df_raw[\"name_processed\"] = df_raw.name.apply(name_process)\n",
    "    df_raw[df_raw.name_processed.isnull()].name_processed =\"missing\" \n",
    "\n",
    "    tk_name_processed , max_length_name_processed ,vocab_size_name_processed = text_vectorizer(\"name_processed\")\n",
    "    name_pad = pad_sequences(tk_name_processed.texts_to_sequences(df_raw.name_processed),maxlen=max_length_name_processed,padding=\"post\")\n",
    "\n",
    "  ############################################################################################################################################\n",
    "\n",
    "  ## BRAND NAME FEATURE\n",
    "    def brand_process(text):\n",
    "        text = re.sub(\"[^A-Za-z0-9 ]\",\"\",text)# REMOVE EVERYTHING EXCEPT THE PROVIDED CHARACTERS\n",
    "        text = text.lower()  # CONVERT TO LOWER CASE\n",
    "        return text\n",
    "\n",
    "\n",
    "    brand_score = dict(df[df.brand_name.notnull()][\"brand_name\"].apply(brand_process).value_counts())\n",
    "\n",
    "    processed_brand_name = [] #storing the barand name after preprocessing\n",
    "    for index,i in df_raw.iterrows() : # for each row in the dataset\n",
    "      \n",
    "        if  pd.isnull(i.brand_name): #if the brand name isnull we follow this\n",
    "          \n",
    "            words = i.name_processed.split() # we will split the name for that datapoint\n",
    "            score  = [] # this variable stores the score for each word that we calculated above\n",
    "            for j in words: # for each word \n",
    "                if j in brand_score.keys(): #if the words in name is present in the keys of brand score dict\n",
    "                    score.append(brand_score[j]) # take the score from the dict and append in the score variable\n",
    "                else: #if the word is not a brand name append -1\n",
    "                    score.append(-1)\n",
    "          # once we get the scores for all the words in the name the word with maximum score woulb be the brand name\n",
    "            if max(score) > 0: #if the maximum score is greater than 0 then it contains a brand name so we append the brand name\n",
    "                processed_brand_name.append(words[score.index(max(score))])\n",
    "            else: # if maximum value is less than 0 then it means no brand name was found so \"missing\" is appended\n",
    "                processed_brand_name.append(\"missing\")\n",
    "              \n",
    "        else: # if the brand_name is not null we follow this\n",
    "            processed_brand_name.append(brand_process(i.brand_name))\n",
    "\n",
    "    df_raw[\"brand_name_processed\"] = processed_brand_name\n",
    "\n",
    "    tk_brand_name,max_length_brand_name,vocab_size_brand_name = text_vectorizer(\"brand_name_processed\")\n",
    "    brand_name_pad = pad_sequences(tk_brand_name.texts_to_sequences(df_raw.brand_name_processed),maxlen=max_length_brand_name,padding=\"post\")\n",
    "\n",
    "  #############################################################################################################################################\n",
    "\n",
    "  ### CATEGORY NAME\n",
    "\n",
    "    def category_name_preprocessing(text):\n",
    "        ''' THIS FUNCTION PREPROCESSES THE TEXT IN \"category_name\" FEATURE'''\n",
    "        text = re.sub(\"[^A-Za-z0-9/ ]\",\"\",text)# REMOVING ALL THE TEXT EXCEPT THE GIVEN CHARACTERS\n",
    "        text = re.sub(\"s \",\" \",text) # REMOVING  \"s\" AT THE END OF THE WORD\n",
    "        text = re.sub(\"s/\",\"/\",text) # REMOVING  \"s\" AT THE END OF THE WORD\n",
    "        text = re.sub(\"  \",\" \",text) # REMOVING ONE SPACE WHERE TWO SPACES ARE PRESENT\n",
    "        text = text.lower() # CONVERTING THE TEXT TO LOWER CASE\n",
    "        return text # RETURNING THE PROCESSED TEXT\n",
    "    \n",
    "    df_raw.category_name[df_raw.category_name.isnull()] = \"missing\"\n",
    "    df_raw[\"category_name_preprocessed\"] = df_raw.category_name.apply(category_name_preprocessing)\n",
    "\n",
    "    df_raw[\"Tier_1\"] = df_raw.category_name_preprocessed.apply(lambda x:   x.split(\"/\")[0] if len(x.split(\"/\"))>=1 else \"missing\")\n",
    "\n",
    "    tk_tier1 , max_length_tier1 ,vocab_size_tier1 = text_vectorizer(\"Tier_1\")\n",
    "    tier1_pad = pad_sequences(tk_tier1.texts_to_sequences(df_raw.Tier_1),maxlen=max_length_tier1,padding=\"post\")\n",
    "\n",
    "\n",
    "    df_raw[\"Tier_2\"] = df_raw.category_name_preprocessed.apply(lambda x:   x.split(\"/\")[1] if len(x.split(\"/\"))>1 else \"missing\")\n",
    "\n",
    "    tk_tier2 , max_length_tier2 ,vocab_size_tier2 = text_vectorizer(\"Tier_2\")\n",
    "    tier2_pad = pad_sequences(tk_tier2.texts_to_sequences(df_raw.Tier_2),maxlen=max_length_tier2,padding=\"post\")\n",
    "\n",
    "    df_raw[\"Tier_3\"] = df_raw.category_name_preprocessed.apply(lambda x:   x.split(\"/\")[2] if len(x.split(\"/\"))>1 else \"missing\")\n",
    "\n",
    "    tk_tier3 , max_length_tier3 ,vocab_size_tier3 = text_vectorizer(\"Tier_3\")\n",
    "    tier3_pad = pad_sequences(tk_tier3.texts_to_sequences(df_raw.Tier_3),maxlen=max_length_tier3,padding=\"post\")\n",
    "\n",
    "  ##################################################################################################################################\n",
    "\n",
    "  # ITEM DESCRIPTION \n",
    "    \n",
    "    def processing_item_description(text):\n",
    "        '''THIS FUNCTION PREPROCESSES THE TEXT IN \"item_description\"'''\n",
    "        text = re.sub(\"\\[rm\\] \",\"\",str(text))\n",
    "        text = decontracted(text)\n",
    "        text = re.sub(\"[^A-Za-z0-9 ]\",\"\",str(text))\n",
    "        text = str(text).lower()\n",
    "        text =  \" \".join([i for i in text.split() if i not in st_words])\n",
    "        if len(text)==0:\n",
    "            text = \"missing\"\n",
    "        return text\n",
    "\n",
    "    df_raw.item_description[df_raw.item_description.isnull()]=\"missing\"\n",
    "    df_raw[\"processed_item_description\"] = df_raw.item_description.apply(processing_item_description)\n",
    "\n",
    "    tk_desc , max_len_desc ,vocab_size_desc = text_vectorizer(\"processed_item_description\")\n",
    "    desc_pad = pad_sequences(tk_desc.texts_to_sequences(df_raw.processed_item_description),maxlen=max_len_desc,padding=\"post\")\n",
    "\n",
    "    x = [item_cond,shipping,brand_name_pad,tier1_pad,tier2_pad,tier3_pad,name_pad,desc_pad]\n",
    "\n",
    "  ##################################################################################################################################\n",
    "\n",
    "  # ITEM CONDITION ID\n",
    "    inp1 = layers.Input(shape=(1))\n",
    "    emb1  = layers.Embedding(6,10,input_length=1)(inp1)\n",
    "    flat1 = layers.Flatten()(emb1)\n",
    "\n",
    "\n",
    "  # SHIPPING \n",
    "    inp2 = layers.Input(shape=(1))\n",
    "    d2 = layers.Dense(10,activation=\"relu\")(inp2)\n",
    "\n",
    "\n",
    "    # BRAND NAME\n",
    "    inp3 = layers.Input(shape= (8))\n",
    "    emb3 = layers.Embedding(vocab_size_brand_name ,16 ,input_length= 8 )(inp3)\n",
    "    flat3 = layers.Flatten()(emb3)\n",
    "\n",
    "    # Tier_1\n",
    "    inp4 = layers.Input(shape = (2))\n",
    "    emb4 = layers.Embedding(vocab_size_tier1, 16 , input_length=2 )(inp4)\n",
    "    flat4 = layers.Flatten()(emb4)\n",
    "\n",
    "    # Tier_2\n",
    "    inp5= layers.Input(shape = (4))\n",
    "    emb5 = layers.Embedding(vocab_size_tier2 , 16 ,input_length= 4 )(inp5)\n",
    "    flat5 = layers.Flatten()(emb5)\n",
    "\n",
    "    # Tier_3\n",
    "    inp6= layers.Input(shape = (6))\n",
    "    emb6 = layers.Embedding(vocab_size_tier3, 16 ,input_length= 6 )(inp6)\n",
    "    flat6 = layers.Flatten()(emb6)\n",
    "\n",
    "    # NAME PROCESSED\n",
    "    inp7= layers.Input(shape = (13))\n",
    "    emb7 = layers.Embedding(vocab_size_name_processed,20 ,input_length= 13 )(inp7)\n",
    "    lstm7 = layers.GRU(64,return_sequences=True)(emb7)\n",
    "    flat7 = layers.Flatten()(lstm7)\n",
    "\n",
    "    # ITEM DESCRIPTION\n",
    "    inp8= layers.Input(shape = (193))\n",
    "    emb8 = layers.Embedding(vocab_size_desc , 40 , input_length= 193 )(inp8)\n",
    "    lstm8 = layers.GRU(64,return_sequences=True)(emb8)\n",
    "    flat8 = layers.Flatten()(lstm8)\n",
    "\n",
    "    concat = layers.Concatenate()([flat1,d2,flat3,flat4,flat5,flat6,flat7,flat8])\n",
    "\n",
    "    dense1 = layers.Dense(512,activation=\"relu\")(concat)\n",
    "    drop2 = layers.Dropout(0.2)(dense1)\n",
    "\n",
    "    dense2 = layers.Dense(256,activation=\"relu\")(drop2)\n",
    "    drop2 = layers.Dropout(0.3)(dense2)\n",
    "\n",
    "\n",
    "    dense3 = layers.Dense(128,activation=\"relu\")(drop2)\n",
    "    drop2 = layers.Dropout(0.4)(dense3)\n",
    "    bn2  = layers.BatchNormalization()(drop2)\n",
    "\n",
    "    dense4 = layers.Dense(1,activation=\"linear\")(bn2)\n",
    "    # MODEL\n",
    "    model =  Model(inputs= [inp1,inp2,inp3,inp4,inp5,inp6,inp7,inp8],outputs=dense4)\n",
    "    model.compile(optimizer=\"adam\",loss=\"mse\",metrics=  tf.keras.metrics.RootMeanSquaredError())\n",
    "    #LOAD WEIGHTS\n",
    "    model.load_weights(\"best.h5\")\n",
    "    \n",
    "    # EVALUATE THE RMSLE VALUES\n",
    "    rmse = model.evaluate(x,np.log(y_price+1),verbose=1,batch_size=1000)\n",
    "  \n",
    "    return rmse[1] # RETURN RMSLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d3fd650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 42s 273ms/step - loss: 0.1853 - root_mean_squared_error: 0.4304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4304217994213104"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EVALUATION OF METRIC FOR VALIDATION DATA\n",
    "function2(df_val,df_val.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fed9872",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
